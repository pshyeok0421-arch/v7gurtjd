# main.py
from __future__ import annotations

import io
import math
import unicodedata
from pathlib import Path
from typing import Dict, List, Tuple

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st
from plotly.subplots import make_subplots

# ----------------------------
# Page / Font (Korean safe)
# ----------------------------
st.set_page_config(
    page_title="ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬",
    layout="wide",
)

st.markdown(
    """
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR&display=swap');
html, body, [class*="css"] {
    font-family: 'Noto Sans KR', 'Malgun Gothic', sans-serif;
}
</style>
""",
    unsafe_allow_html=True,
)

PLOTLY_FONT = "Malgun Gothic, Apple SD Gothic Neo, Noto Sans KR, sans-serif"

# ----------------------------
# Constants / Metadata
# ----------------------------
SCHOOLS = ["ì „ì²´", "ì†¡ë„ê³ ", "í•˜ëŠ˜ê³ ", "ì•„ë¼ê³ ", "ë™ì‚°ê³ "]

SCHOOL_META = pd.DataFrame(
    [
        {"í•™êµëª…": "ì†¡ë„ê³ ", "EC ëª©í‘œ": 1.0, "ê°œì²´ìˆ˜(ì‹œíŠ¸)": 29, "ìƒ‰ìƒ": "#1f77b4"},
        {"í•™êµëª…": "í•˜ëŠ˜ê³ ", "EC ëª©í‘œ": 2.0, "ê°œì²´ìˆ˜(ì‹œíŠ¸)": 45, "ìƒ‰ìƒ": "#2ca02c"},  # ìµœì 
        {"í•™êµëª…": "ì•„ë¼ê³ ", "EC ëª©í‘œ": 4.0, "ê°œì²´ìˆ˜(ì‹œíŠ¸)": 106, "ìƒ‰ìƒ": "#ff7f0e"},
        {"í•™êµëª…": "ë™ì‚°ê³ ", "EC ëª©í‘œ": 8.0, "ê°œì²´ìˆ˜(ì‹œíŠ¸)": 58, "ìƒ‰ìƒ": "#d62728"},
    ]
)

OPTIMAL_EC = 2.0
DATA_DIR = Path(__file__).resolve().parent / "data"

ENV_REQUIRED_COLS = ["time", "temperature", "humidity", "ph", "ec"]

# Growth columns (Korean)
GROWTH_REQUIRED_COLS = ["ê°œì²´ë²ˆí˜¸", "ì ìˆ˜(ì¥)", "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€í•˜ë¶€ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"]


# ----------------------------
# Unicode-safe file matching
# ----------------------------
def _norm_all(s: str) -> Tuple[str, str]:
    """Return (NFC, NFD) normalized versions."""
    return (unicodedata.normalize("NFC", s), unicodedata.normalize("NFD", s))


def _path_name_norms(p: Path) -> Tuple[str, str]:
    return _norm_all(p.name)


def _equals_unicode(a: str, b: str) -> bool:
    a_nfc, a_nfd = _norm_all(a)
    b_nfc, b_nfd = _norm_all(b)
    return (a_nfc == b_nfc) or (a_nfd == b_nfd) or (a_nfc == b_nfd) or (a_nfd == b_nfc)


def find_file_by_exact_name(data_dir: Path, target_name: str) -> Path | None:
    """Iterate files and match target_name using NFC/NFD bidirectional comparison."""
    for p in data_dir.iterdir():
        if p.is_file():
            if _equals_unicode(p.name, target_name):
                return p
    return None


def find_first_xlsx(data_dir: Path) -> Path | None:
    """Iterate files and return first .xlsx (unicode-safe, no glob)."""
    for p in data_dir.iterdir():
        if p.is_file():
            nfc, nfd = _path_name_norms(p)
            if nfc.lower().endswith(".xlsx") or nfd.lower().endswith(".xlsx"):
                return p
    return None


# ----------------------------
# Cached data loaders
# ----------------------------
@st.cache_data(show_spinner=False)
def load_environment_csvs(data_dir: Path) -> Dict[str, pd.DataFrame]:
    """Load all school environment CSVs into dict by school name (without hardcoding path joins)."""
    wanted = {
        "ì†¡ë„ê³ ": "ì†¡ë„ê³ _í™˜ê²½ë°ì´í„°.csv",
        "í•˜ëŠ˜ê³ ": "í•˜ëŠ˜ê³ _í™˜ê²½ë°ì´í„°.csv",
        "ì•„ë¼ê³ ": "ì•„ë¼ê³ _í™˜ê²½ë°ì´í„°.csv",
        "ë™ì‚°ê³ ": "ë™ì‚°ê³ _í™˜ê²½ë°ì´í„°.csv",
    }

    out: Dict[str, pd.DataFrame] = {}

    for school, fname in wanted.items():
        p = find_file_by_exact_name(data_dir, fname)
        if p is None:
            continue
        df = pd.read_csv(p)
        # Ensure columns exist
        missing = [c for c in ENV_REQUIRED_COLS if c not in df.columns]
        if missing:
            raise ValueError(f"[{school}] í™˜ê²½ ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

        # Parse time
        df = df.copy()
        df["time"] = pd.to_datetime(df["time"], errors="coerce")
        df = df.dropna(subset=["time"])
        # numeric coercion
        for col in ["temperature", "humidity", "ph", "ec"]:
            df[col] = pd.to_numeric(df[col], errors="coerce")
        df = df.dropna(subset=["temperature", "humidity", "ph", "ec"])

        df["í•™êµ"] = school
        out[school] = df

    return out


@st.cache_data(show_spinner=False)
def load_growth_xlsx(data_dir: Path) -> Dict[str, pd.DataFrame]:
    """Load growth results xlsx (all sheets) without hardcoding sheet names."""
    xlsx_path = find_file_by_exact_name(data_dir, "4ê°œêµ_ìƒìœ¡ê²°ê³¼ë°ì´í„°.xlsx")
    if xlsx_path is None:
        # fallback: any xlsx
        xlsx_path = find_first_xlsx(data_dir)
    if xlsx_path is None:
        return {}

    xls = pd.ExcelFile(xlsx_path, engine="openpyxl")
    sheets = xls.sheet_names

    out: Dict[str, pd.DataFrame] = {}

    # map sheet -> school by unicode-normalized containment, not hardcoded exact list
    school_candidates = ["ë™ì‚°ê³ ", "ì†¡ë„ê³ ", "ì•„ë¼ê³ ", "í•˜ëŠ˜ê³ "]

    for sh in sheets:
        sh_nfc, sh_nfd = _norm_all(sh)
        matched_school = None
        for s in school_candidates:
            s_nfc, s_nfd = _norm_all(s)
            if (s_nfc in sh_nfc) or (s_nfd in sh_nfd) or (s_nfc in sh_nfd) or (s_nfd in sh_nfc):
                matched_school = s
                break

        df = pd.read_excel(xls, sheet_name=sh, engine="openpyxl")
        if df is None or df.empty:
            continue

        # If it doesn't match any known school name, still keep it under sheet name
        key = matched_school if matched_school is not None else sh

        # Validate required columns (allow minor whitespace)
        df = df.copy()
        df.columns = [str(c).strip() for c in df.columns]

        missing = [c for c in GROWTH_REQUIRED_COLS if c not in df.columns]
        if missing:
            # keep but warn later, donâ€™t crash whole app
            df["_missing_cols"] = ", ".join(missing)

        # numeric columns
        for col in ["ì ìˆ˜(ì¥)", "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ì§€í•˜ë¶€ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"]:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors="coerce")

        df["í•™êµ"] = key
        out[key] = df

    return out


# ----------------------------
# Helpers
# ----------------------------
def get_target_ec(school: str) -> float | None:
    row = SCHOOL_META[SCHOOL_META["í•™êµëª…"] == school]
    if row.empty:
        return None
    return float(row.iloc[0]["EC ëª©í‘œ"])


def get_color(school: str) -> str:
    row = SCHOOL_META[SCHOOL_META["í•™êµëª…"] == school]
    if row.empty:
        return "#888888"
    return str(row.iloc[0]["ìƒ‰ìƒ"])


def combine_env(env_dict: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    if not env_dict:
        return pd.DataFrame(columns=ENV_REQUIRED_COLS + ["í•™êµ"])
    return pd.concat(env_dict.values(), ignore_index=True)


def combine_growth(growth_dict: Dict[str, pd.DataFrame]) -> pd.DataFrame:
    if not growth_dict:
        return pd.DataFrame(columns=GROWTH_REQUIRED_COLS + ["í•™êµ"])
    return pd.concat(growth_dict.values(), ignore_index=True)


def safe_mean(series: pd.Series) -> float | None:
    s = pd.to_numeric(series, errors="coerce").dropna()
    if s.empty:
        return None
    return float(s.mean())


def format_num(x: float | None, digits: int = 2) -> str:
    if x is None or (isinstance(x, float) and (math.isnan(x) or math.isinf(x))):
        return "-"
    return f"{x:.{digits}f}"


def linear_fit_line(df: pd.DataFrame, x_col: str, y_col: str) -> Tuple[float, float] | None:
    """
    Fit y = a*x + b using least squares without numpy/statsmodels.
    Return (a, b) or None.
    """
    x = pd.to_numeric(df[x_col], errors="coerce")
    y = pd.to_numeric(df[y_col], errors="coerce")
    tmp = pd.DataFrame({"x": x, "y": y}).dropna()
    if len(tmp) < 2:
        return None

    x = tmp["x"]
    y = tmp["y"]
    x_mean = x.mean()
    y_mean = y.mean()

    denom = ((x - x_mean) ** 2).sum()
    if denom == 0:
        return None

    a = (((x - x_mean) * (y - y_mean)).sum()) / denom
    b = y_mean - a * x_mean
    return float(a), float(b)


def scatter_with_fit(df: pd.DataFrame, x: str, y: str, title: str) -> go.Figure:
    fig = px.scatter(df, x=x, y=y, hover_data=["í•™êµ"], title=title)
    fig.update_layout(font=dict(family=PLOTLY_FONT))

    fit = linear_fit_line(df, x, y)
    if fit is not None:
        a, b = fit
        x_min = float(pd.to_numeric(df[x], errors="coerce").min())
        x_max = float(pd.to_numeric(df[x], errors="coerce").max())
        xs = [x_min, x_max]
        ys = [a * x_min + b, a * x_max + b]
        fig.add_trace(go.Scatter(x=xs, y=ys, mode="lines", name="íšŒê·€ì„ "))

    # correlation (Pearson)
    corr = pd.to_numeric(df[x], errors="coerce").corr(pd.to_numeric(df[y], errors="coerce"))
    if corr is not None and not (isinstance(corr, float) and math.isnan(corr)):
        fig.add_annotation(
            x=0.01,
            y=0.99,
            xref="paper",
            yref="paper",
            showarrow=False,
            align="left",
            text=f"ìƒê´€ê³„ìˆ˜ r = {corr:.3f}",
            borderpad=6,
        )
    return fig


def df_to_csv_bytes(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False).encode("utf-8-sig")


def df_to_xlsx_bytes(df: pd.DataFrame) -> bytes:
    buffer = io.BytesIO()
    df.to_excel(buffer, index=False, engine="openpyxl")
    buffer.seek(0)
    return buffer.getvalue()


def multi_sheet_xlsx_bytes(dfs: Dict[str, pd.DataFrame]) -> bytes:
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
        for name, df in dfs.items():
            sheet = str(name)[:31]  # Excel sheet limit
            df.to_excel(writer, index=False, sheet_name=sheet)
    buffer.seek(0)
    return buffer.getvalue()


# ----------------------------
# Sidebar
# ----------------------------
st.title("ğŸŒ± ê·¹ì§€ì‹ë¬¼ ìµœì  EC ë†ë„ ì—°êµ¬")

selected_school = st.sidebar.selectbox("í•™êµ ì„ íƒ", SCHOOLS, index=0)

# ----------------------------
# Load data with safety
# ----------------------------
with st.spinner("ë°ì´í„° ë¡œë”© ì¤‘..."):
    try:
        env_dict = load_environment_csvs(DATA_DIR)
    except Exception as e:
        st.error(f"í™˜ê²½ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        env_dict = {}

    try:
        growth_dict = load_growth_xlsx(DATA_DIR)
    except Exception as e:
        st.error(f"ìƒìœ¡ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        growth_dict = {}

env_all = combine_env(env_dict)
growth_all = combine_growth(growth_dict)

if env_all.empty:
    st.error("í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— CSV 4ê°œê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
if growth_all.empty:
    st.error("ìƒìœ¡ ê²°ê³¼ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. data/ í´ë”ì— XLSXê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

# Filtered
if selected_school != "ì „ì²´":
    env_view = env_all[env_all["í•™êµ"] == selected_school].copy()
    growth_view = growth_all[growth_all["í•™êµ"] == selected_school].copy()
else:
    env_view = env_all.copy()
    growth_view = growth_all.copy()

# ----------------------------
# Tabs
# ----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ“– ì‹¤í—˜ ê°œìš”", "ğŸŒ¡ï¸ í™˜ê²½ ë°ì´í„°", "ğŸ“Š ìƒìœ¡ ê²°ê³¼"])

# =========================================================
# Tab 1: Overview
# =========================================================
with tab1:
    st.subheader("ì—°êµ¬ ë°°ê²½ ë° ëª©ì ")
    st.write(
        """
ê·¹ì§€ì‹ë¬¼ì€ ì˜¨ë„Â·ìŠµë„Â·pH ê°™ì€ í™˜ê²½ ì¡°ê±´ë¿ ì•„ë‹ˆë¼ **ì–‘ì•¡ì˜ EC(ì „ê¸°ì „ë„ë„)** ë³€í™”ì— ë”°ë¼ ìƒìœ¡ì´ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ë³¸ ì—°êµ¬ëŠ” **í•™êµë³„ë¡œ ì„œë¡œ ë‹¤ë¥¸ EC ì¡°ê±´(1.0 / 2.0 / 4.0 / 8.0)**ì—ì„œ ì¬ë°°í•œ ê·¹ì§€ì‹ë¬¼ì˜ ìƒìœ¡ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬  
**ìµœì  EC ë†ë„(ìƒì¤‘ëŸ‰ ì¤‘ì‹¬)**ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.
"""
    )

    st.subheader("í•™êµë³„ EC ì¡°ê±´")
    meta_show = SCHOOL_META.copy()
    meta_show["EC ëª©í‘œ"] = meta_show["EC ëª©í‘œ"].map(lambda v: f"{v:.1f}")
    st.dataframe(meta_show, use_container_width=True, hide_index=True)

    # KPI cards
    total_n = None
    if not growth_all.empty and "ê°œì²´ë²ˆí˜¸" in growth_all.columns:
        total_n = int(growth_all["ê°œì²´ë²ˆí˜¸"].dropna().nunique())
    else:
        total_n = int(len(growth_all)) if not growth_all.empty else 0

    avg_temp = safe_mean(env_view["temperature"]) if not env_view.empty else None
    avg_hum = safe_mean(env_view["humidity"]) if not env_view.empty else None

    c1, c2, c3, c4 = st.columns(4)
    c1.metric("ì´ ê°œì²´ìˆ˜", f"{total_n:,}")
    c2.metric("í‰ê·  ì˜¨ë„(Â°C)", format_num(avg_temp, 2))
    c3.metric("í‰ê·  ìŠµë„(%)", format_num(avg_hum, 2))
    c4.metric("ìµœì  EC(ê°€ì •)", f"{OPTIMAL_EC:.1f} (í•˜ëŠ˜ê³ )")

# =========================================================
# Tab 2: Environment
# =========================================================
with tab2:
    st.subheader("í•™êµë³„ í™˜ê²½ í‰ê·  ë¹„êµ")

    if env_all.empty:
        st.stop()

    # Summary by school (all schools)
    env_summary = (
        env_all.groupby("í•™êµ", as_index=False)
        .agg(
            í‰ê· ì˜¨ë„=("temperature", "mean"),
            í‰ê· ìŠµë„=("humidity", "mean"),
            í‰ê· pH=("ph", "mean"),
            ì‹¤ì¸¡ECí‰ê· =("ec", "mean"),
        )
        .copy()
    )
    # Add target EC
    env_summary["ëª©í‘œEC"] = env_summary["í•™êµ"].map(lambda s: get_target_ec(s))

    fig = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ì˜¨ë„", "í‰ê·  ìŠµë„", "í‰ê·  pH", "ëª©í‘œ EC vs ì‹¤ì¸¡ EC"),
    )

    # Top-left: temp
    fig.add_trace(
        go.Bar(
            x=env_summary["í•™êµ"],
            y=env_summary["í‰ê· ì˜¨ë„"],
            name="í‰ê·  ì˜¨ë„",
        ),
        row=1,
        col=1,
    )
    # Top-right: humidity
    fig.add_trace(
        go.Bar(
            x=env_summary["í•™êµ"],
            y=env_summary["í‰ê· ìŠµë„"],
            name="í‰ê·  ìŠµë„",
        ),
        row=1,
        col=2,
    )
    # Bottom-left: pH
    fig.add_trace(
        go.Bar(
            x=env_summary["í•™êµ"],
            y=env_summary["í‰ê· pH"],
            name="í‰ê·  pH",
        ),
        row=2,
        col=1,
    )
    # Bottom-right: target vs measured EC (dual bar)
    fig.add_trace(
        go.Bar(
            x=env_summary["í•™êµ"],
            y=env_summary["ëª©í‘œEC"],
            name="ëª©í‘œ EC",
        ),
        row=2,
        col=2,
    )
    fig.add_trace(
        go.Bar(
            x=env_summary["í•™êµ"],
            y=env_summary["ì‹¤ì¸¡ECí‰ê· "],
            name="ì‹¤ì¸¡ EC í‰ê· ",
        ),
        row=2,
        col=2,
    )

    fig.update_layout(
        height=650,
        barmode="group",
        font=dict(family=PLOTLY_FONT),
        margin=dict(l=40, r=20, t=80, b=40),
        showlegend=True,
    )
    st.plotly_chart(fig, use_container_width=True)

    st.subheader("ì„ íƒí•œ í•™êµ ì‹œê³„ì—´")

    if env_view.empty:
        st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” í™˜ê²½ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # Temperature
        fig_t = px.line(env_view.sort_values("time"), x="time", y="temperature", title="ì˜¨ë„ ë³€í™”")
        fig_t.update_layout(font=dict(family=PLOTLY_FONT))
        st.plotly_chart(fig_t, use_container_width=True)

        # Humidity
        fig_h = px.line(env_view.sort_values("time"), x="time", y="humidity", title="ìŠµë„ ë³€í™”")
        fig_h.update_layout(font=dict(family=PLOTLY_FONT))
        st.plotly_chart(fig_h, use_container_width=True)

        # EC with target line
        fig_ec = px.line(env_view.sort_values("time"), x="time", y="ec", title="EC ë³€í™”")
        target = None
        if selected_school != "ì „ì²´":
            target = get_target_ec(selected_school)
        fig_ec.update_layout(font=dict(family=PLOTLY_FONT))
        if target is not None:
            fig_ec.add_hline(y=target, line_dash="dash", annotation_text=f"ëª©í‘œ EC {target:.1f}", annotation_position="top left")
        st.plotly_chart(fig_ec, use_container_width=True)

    with st.expander("í™˜ê²½ ë°ì´í„° ì›ë³¸ í…Œì´ë¸” / CSV ë‹¤ìš´ë¡œë“œ"):
        st.dataframe(env_view, use_container_width=True, hide_index=True)
        st.download_button(
            label="CSV ë‹¤ìš´ë¡œë“œ",
            data=df_to_csv_bytes(env_view),
            file_name="í™˜ê²½ë°ì´í„°_í•„í„°ë§.csv" if selected_school == "ì „ì²´" else f"í™˜ê²½ë°ì´í„°_{selected_school}.csv",
            mime="text/csv",
        )

# =========================================================
# Tab 3: Growth results
# =========================================================
with tab3:
    st.subheader("ğŸ¥‡ í•µì‹¬ ê²°ê³¼: ECë³„ í‰ê·  ìƒì¤‘ëŸ‰")

    if growth_all.empty:
        st.stop()

    # Attach target EC by school
    growth_all_ec = growth_all.copy()
    growth_all_ec["EC ëª©í‘œ"] = growth_all_ec["í•™êµ"].map(lambda s: get_target_ec(s))

    # If user filtered to one school, keep analysis consistent (still show EC buckets on available data)
    growth_use = growth_all_ec if selected_school == "ì „ì²´" else growth_all_ec[growth_all_ec["í•™êµ"] == selected_school].copy()

    if "ìƒì¤‘ëŸ‰(g)" not in growth_use.columns or growth_use["ìƒì¤‘ëŸ‰(g)"].dropna().empty:
        st.error("ìƒì¤‘ëŸ‰(g) ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.stop()

    # Group by EC target (1,2,4,8)
    ec_group = (
        growth_use.dropna(subset=["EC ëª©í‘œ"])
        .groupby("EC ëª©í‘œ", as_index=False)
        .agg(
            í‰ê· ìƒì¤‘ëŸ‰=("ìƒì¤‘ëŸ‰(g)", "mean"),
            í‰ê· ììˆ˜=("ì ìˆ˜(ì¥)", "mean"),
            í‰ê· ì§€ìƒë¶€ê¸¸ì´=("ì§€ìƒë¶€ ê¸¸ì´(mm)", "mean"),
            ê°œì²´ìˆ˜=("ê°œì²´ë²ˆí˜¸", "count"),
        )
        .sort_values("EC ëª©í‘œ")
    )

    if ec_group.empty:
        st.error("EC ëª©í‘œ ê°’ìœ¼ë¡œ ë¬¶ì„ ìˆ˜ ìˆëŠ” ìƒìœ¡ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    # Highlight max mean weight
    max_row = ec_group.loc[ec_group["í‰ê· ìƒì¤‘ëŸ‰"].idxmax()]
    best_ec = float(max_row["EC ëª©í‘œ"])
    best_weight = float(max_row["í‰ê· ìƒì¤‘ëŸ‰"])

    k1, k2, k3, k4 = st.columns(4)
    k1.metric("ìµœëŒ€ í‰ê·  ìƒì¤‘ëŸ‰", f"{best_weight:.3f} g")
    k2.metric("í•´ë‹¹ EC", f"{best_ec:.1f}")
    # emphasize optimal assumption
    k3.metric("ê°€ì • ìµœì  EC(í•˜ëŠ˜ê³ )", f"{OPTIMAL_EC:.1f}")
    k4.metric("ì„ íƒ ë²”ìœ„", "ì „ì²´" if selected_school == "ì „ì²´" else selected_school)

    st.subheader("ECë³„ ìƒìœ¡ ë¹„êµ (2x2)")

    fig2 = make_subplots(
        rows=2,
        cols=2,
        subplot_titles=("í‰ê·  ìƒì¤‘ëŸ‰(g) â­", "í‰ê·  ì ìˆ˜(ì¥)", "í‰ê·  ì§€ìƒë¶€ ê¸¸ì´(mm)", "ê°œì²´ìˆ˜"),
    )

    # Weight
    fig2.add_trace(go.Bar(x=ec_group["EC ëª©í‘œ"], y=ec_group["í‰ê· ìƒì¤‘ëŸ‰"], name="í‰ê·  ìƒì¤‘ëŸ‰"), row=1, col=1)
    # Leaves
    fig2.add_trace(go.Bar(x=ec_group["EC ëª©í‘œ"], y=ec_group["í‰ê· ììˆ˜"], name="í‰ê·  ì ìˆ˜"), row=1, col=2)
    # Shoot length
    fig2.add_trace(go.Bar(x=ec_group["EC ëª©í‘œ"], y=ec_group["í‰ê· ì§€ìƒë¶€ê¸¸ì´"], name="í‰ê·  ì§€ìƒë¶€ ê¸¸ì´"), row=2, col=1)
    # Count
    fig2.add_trace(go.Bar(x=ec_group["EC ëª©í‘œ"], y=ec_group["ê°œì²´ìˆ˜"], name="ê°œì²´ìˆ˜"), row=2, col=2)

    fig2.update_layout(
        height=650,
        barmode="group",
        font=dict(family=PLOTLY_FONT),
        margin=dict(l=40, r=20, t=80, b=40),
        showlegend=False,
    )

    # Mark EC 2.0 as optimal (vertical line on first subplot feel via annotation)
    fig2.add_vline(x=OPTIMAL_EC, line_dash="dash", annotation_text="ìµœì (í•˜ëŠ˜ê³  EC 2.0)", annotation_position="top")
    st.plotly_chart(fig2, use_container_width=True)

    st.subheader("í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬")

    if selected_school == "ì „ì²´":
        fig_box = px.box(
            growth_all_ec.dropna(subset=["ìƒì¤‘ëŸ‰(g)"]),
            x="í•™êµ",
            y="ìƒì¤‘ëŸ‰(g)",
            points="outliers",
            title="í•™êµë³„ ìƒì¤‘ëŸ‰ ë¶„í¬ (Box Plot)",
            color="í•™êµ",
            color_discrete_map={r["í•™êµëª…"]: r["ìƒ‰ìƒ"] for _, r in SCHOOL_META.iterrows()},
        )
    else:
        fig_box = px.box(
            growth_use.dropna(subset=["ìƒì¤‘ëŸ‰(g)"]),
            x="í•™êµ",
            y="ìƒì¤‘ëŸ‰(g)",
            points="outliers",
            title="ì„ íƒí•œ í•™êµ ìƒì¤‘ëŸ‰ ë¶„í¬ (Box Plot)",
            color="í•™êµ",
            color_discrete_map={selected_school: get_color(selected_school)},
        )
    fig_box.update_layout(font=dict(family=PLOTLY_FONT))
    st.plotly_chart(fig_box, use_container_width=True)

    st.subheader("ìƒê´€ê´€ê³„ ë¶„ì„ (íšŒê·€ì„ ì€ statsmodels ì—†ì´ ì§ì ‘ ê³„ì‚°)")

    # Scatter 1: Leaves vs Weight
    s1 = growth_use.dropna(subset=["ì ìˆ˜(ì¥)", "ìƒì¤‘ëŸ‰(g)"])
    if len(s1) >= 2:
        fig_s1 = scatter_with_fit(s1, "ì ìˆ˜(ì¥)", "ìƒì¤‘ëŸ‰(g)", "ì ìˆ˜ vs ìƒì¤‘ëŸ‰")
        st.plotly_chart(fig_s1, use_container_width=True)
    else:
        st.info("ì ìˆ˜ vs ìƒì¤‘ëŸ‰ ì‚°ì ë„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    # Scatter 2: Shoot length vs Weight
    s2 = growth_use.dropna(subset=["ì§€ìƒë¶€ ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)"])
    if len(s2) >= 2:
        fig_s2 = scatter_with_fit(s2, "ì§€ìƒë¶€ ê¸¸ì´(mm)", "ìƒì¤‘ëŸ‰(g)", "ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰")
        st.plotly_chart(fig_s2, use_container_width=True)
    else:
        st.info("ì§€ìƒë¶€ ê¸¸ì´ vs ìƒì¤‘ëŸ‰ ì‚°ì ë„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    with st.expander("í•™êµë³„ ìƒìœ¡ ë°ì´í„° ì›ë³¸ / XLSX ë‹¤ìš´ë¡œë“œ"):
        st.dataframe(growth_view, use_container_width=True, hide_index=True)

        # Download: if ì „ì²´ -> multi sheet, else single sheet
        if selected_school == "ì „ì²´":
            # Keep only the 4 known schools if present; otherwise include all loaded keys
            dfs = {}
            for school in ["ë™ì‚°ê³ ", "ì†¡ë„ê³ ", "ì•„ë¼ê³ ", "í•˜ëŠ˜ê³ "]:
                if school in growth_dict:
                    dfs[school] = growth_dict[school]
            if not dfs:
                dfs = growth_dict
            xlsx_bytes = multi_sheet_xlsx_bytes(dfs)
            st.download_button(
                label="XLSX ë‹¤ìš´ë¡œë“œ (ì‹œíŠ¸ í¬í•¨)",
                data=xlsx_bytes,
                file_name="ìƒìœ¡ê²°ê³¼_ì „ì²´.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
        else:
            xlsx_bytes = df_to_xlsx_bytes(growth_view)
            st.download_button(
                label="XLSX ë‹¤ìš´ë¡œë“œ (ì„ íƒ í•™êµ)",
                data=xlsx_bytes,
                file_name=f"ìƒìœ¡ê²°ê³¼_{selected_school}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )
 
